# Local LLM Chat v1.6.3 マニュアル

## 概要

Local LLM Chatは、ローカルで動作するLLMサーバー（LM Studio、Ollamaなど）と連携するWebベースのチャットインターフェースです。完全オフラインで動作し、プライバシーを重視した設計になっています。

---

## 動作要件

- **ブラウザ**: Chrome、Firefox、Safari、Edge（モダンブラウザ）
- **LLMサーバー**: LM Studio または Ollama
- **デフォルトURL**: `http://localhost:1234/v1`

---

## 起動方法

1. LM Studioを起動し、モデルをロード
2. LM Studioの「Local Server」を開始（デフォルト: ポート1234）
3. `local_llm_chat_v1.6.3.html` をブラウザで開く
4. モデルが自動的にドロップダウンに表示される

---

## 画面構成

### ヘッダー
- **タイトル**: Local LLM Chat v1.6.3
- **モデル選択**: ロードされているモデルを選択（👁️マークはVision対応）
- **🔄 Refresh**: モデル一覧を再取得
- **🗑 Clear**: 会話履歴をクリア
- **💾 Export**: 会話履歴をJSONでエクスポート
- **⚙️ Settings**: 設定パネルを開く

### 入力エリア（画面下部）
- **📷 Image**: 画像ファイルを添付（複数可）
- **📎 File**: テキスト/PDFファイルを添付（複数可）
- **🔍 深掘り**: 深掘りモードのON/OFF
- **テキスト入力欄**: メッセージを入力
- **🚀 Send**: メッセージを送信
- **⏹ Stop**: 生成を中断
- **📋 Preset**: プリセットプロンプトを挿入

---

## 主な機能

### 1. チャット機能
- **ストリーミング応答**: リアルタイムでAIの回答を表示
- **Markdown対応**: コードブロック、リスト、表などを整形表示
- **メッセージ操作**:
  - 📋 Copy: メッセージをコピー
  - 🗑 Delete: メッセージを削除
  - ✏️ Edit: ユーザーメッセージを編集・再送信
  - 🔄 Regenerate: AI応答を再生成

### 2. 画像・ファイル添付
- **画像添付**: Vision対応モデルで画像を認識
  - 📷 Imageボタン、ペースト（Ctrl+V）、ドラッグ＆ドロップ対応
  - 複数画像の同時添付可能
  - サムネイルプレビュー表示
- **ファイル添付**: テキストファイルやPDFの内容を送信
  - 対応形式: .txt, .md, .json, .csv, .xml, .html, .css, .js, .py, .pdf など
  - PDF: テキスト抽出してLLMに送信

### 3. Vision対応モデル表示
- ドロップダウンにVision対応モデルは👁️アイコン付きで表示
- 対応キーワード: vision, llava, gemma-3, pixtral, qwen-vl など

### 4. 深掘りモード
🔍深掘りボタンで有効化すると、より深く分析した回答を促します：
- 根本的な原因や背景の分析
- 異なる視点や解釈の可能性
- 関連する概念や理論との繋がり
- 潜在的な問題点や限界
- 実践的な応用や次のステップ

### 5. プリセットプロンプト
📋 Presetボタンで定型プロンプトを挿入：
- 🏥 疾患解説
- 💊 鑑別診断
- 📄 文章要約
- 📝 論文査読
- 📈 統計解析
- ✉️ 英文メール作成

Settingsでプリセットの編集・追加も可能です。

---

## 設定項目

### 基本設定
| 項目 | 説明 | デフォルト |
|------|------|-----------|
| 🌙 Dark Mode | ダークモードの切替 | OFF |
| 🔗 Base URL | LLMサーバーのURL | http://localhost:1234/v1 |
| 🔑 API Key | 認証キー | lmstudio |
| Temperature | 創造性（0=安定、2=創造的） | 0.7 |
| Max Tokens | 最大出力トークン数 | 2048 |
| 送信キー | メッセージ送信のキー設定 | Enter で送信 |

### 送信キー設定
| 設定 | Enter | Shift+Enter | Ctrl/Cmd+Enter |
|------|-------|-------------|----------------|
| Enter で送信 | 送信 | 改行 | - |
| Ctrl+Enter で送信 | 改行 | 改行 | 送信 |

### 応答スタイル
| スタイル | 説明 |
|----------|------|
| 簡潔 | 要点のみを短く |
| 標準 | バランスの取れた回答 |
| 詳細 | 背景や具体例を含む |
| 専門的 | 技術的詳細重視 |

### ユーザープロフィール
| 項目 | 説明 |
|------|------|
| 専門レベル | 初心者〜専門家 |
| 職業/専門分野 | 例: 放射線科医、学生 |
| 興味・関心 | 例: CT画像診断、機械学習 |

### データ管理
- **🔄 設定をデフォルトに戻す**: 設定のみリセット
- **🗑 すべての保存データを消す**: 履歴・設定・プリセットを全削除

---

## キーボードショートカット

| ショートカット | 動作 |
|---------------|------|
| Enter | メッセージ送信（設定による） |
| Ctrl/Cmd + Enter | メッセージ送信（設定による） |
| Shift + Enter | 改行 |
| Ctrl/Cmd + V | 画像をペースト |
| Ctrl/Cmd + K | 履歴クリア |
| Esc | パネルを閉じる |

※ 送信キーは Settings で「Enter で送信」または「Ctrl+Enter で送信」に切り替え可能

---

## トラブルシューティング

### モデルが表示されない
1. LM Studioが起動しているか確認
2. Local Serverが開始されているか確認
3. Base URLが正しいか確認（デフォルト: http://localhost:1234/v1）
4. 🔄 Refreshボタンをクリック

### 画像が認識されない
1. Vision対応モデル（👁️マーク付き）を選択しているか確認
2. 画像サイズが20MB以下か確認
3. モデルサイズは30B以上を推奨

### 応答が遅い・途切れる
1. Max Tokensを減らす
2. より小さいモデルに変更
3. PCのメモリ・GPU使用状況を確認

### 応答が途中で消える
1. Settings → 「🗑 すべての保存データを消す」で履歴をクリア
2. ページを強制リロード（Cmd+Shift+R または Ctrl+Shift+R）
3. 古いキャッシュが残っている可能性があるため、ブラウザキャッシュをクリア

---

## データ保存について

すべてのデータはブラウザのlocalStorageに保存されます：
- `chatHistory_v1.6`: 会話履歴
- `chatSettings_v1.6`: 設定
- `chatPresets_v1.6`: カスタムプリセット

データはブラウザを閉じても保持されます。プライベートモード/シークレットモードでは保存されません。

---

## 技術情報

- **対応API**: OpenAI互換API（LM Studio、Ollama、LocalAI など）
- **外部ライブラリ**: marked.js（Markdown）、PDF.js（PDF抽出）
- **オフライン対応**: すべてのライブラリはローカルに同梱

---

## バージョン履歴

### v1.6.3 (2025-12-23)
- v1.6.2 と同内容（バージョン番号整理）

### v1.6.2 (2025-12-23)
- 重複メッセージ送信バグの修正
- ストリーミングエラー時のコンテンツ保持
- 送信キー設定（Enter / Ctrl+Enter）の追加
- キャッシュバスティング追加
- デバッグログ機能

### v1.6.1 (2025-12-22)
- Vision対応モデルの表示（👁️アイコン）
- モデル一覧のアルファベット順ソート
- 画像サムネイルプレビュー
- ユーザーメッセージの編集機能
- 深掘りモード

### v1.6 (2025-12-22)
- 設定リセット機能
- 全データクリア機能
- 複数ファイル添付対応
- 外部ファイル分割（HTML + CSS + JS）

詳細は `CHANGELOG.md` を参照してください。
